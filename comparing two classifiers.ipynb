{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8zDIHLflgYT"
   },
   "source": [
    "1. Load the BBC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "5Qmj43-klenQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0      tech  tv future in the hands of viewers with home th...\n",
       "1  business  worldcom boss  left books alone  former worldc...\n",
       "2     sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3     sport  yeading face newcastle in fa cup premiership s..."
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the BBC news corpus \n",
    "df = pd.read_csv('bbc-text.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYfx_uAgmz96"
   },
   "source": [
    "2. Pre-process the data if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sarinous/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sarinous/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category                                               text  \\\n",
      "0      tech  tv future hands viewers home theatre systems p...   \n",
      "1  business  worldcom boss left books alone former worldcom...   \n",
      "2     sport  tigers wary farrell gamble leicester say rushe...   \n",
      "3     sport  yeading face newcastle fa cup premiership side...   \n",
      "\n",
      "                                              tokens  category_encoded  \n",
      "0  [tv, future, hand, viewer, home, theatre, syst...                 4  \n",
      "1  [worldcom, bos, left, book, alone, former, wor...                 0  \n",
      "2  [tiger, wary, farrell, gamble, leicester, say,...                 3  \n",
      "3  [yeading, face, newcastle, fa, cup, premiershi...                 3  \n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Check for missing values and ensure column is not missing\n",
    "df.dropna(subset=['text', 'category'], inplace=True) \n",
    "\n",
    "# Convert text to lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "df['text'] = df['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Tokenize and lemmatize the text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x.split()])\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "print(df.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMrH-Y75m6YB"
   },
   "source": [
    "3. Split the data into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1780\n",
      "Test set size: 445\n",
      "\n",
      "Category Encoding Mapping:\n",
      "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode the 'category' column into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df['text']  #raw text\n",
    "y = df['category_encoded']  #encoded categories\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of the splits\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# View the mapping of categories to encoded values\n",
    "print(\"Category Encoding Mapping:\")\n",
    "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT9y-xh7lmtY"
   },
   "source": [
    "4. Create the first topic classifier. Include a vectorizer if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) \n",
    "\n",
    "# Create the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEiAaM1Flwit"
   },
   "source": [
    "5. Report on training metrics of the first classifier. Use the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00       409\n",
      "entertainment       1.00      1.00      1.00       305\n",
      "     politics       0.99      0.99      0.99       334\n",
      "        sport       1.00      1.00      1.00       413\n",
      "         tech       0.99      1.00      0.99       319\n",
      "\n",
      "     accuracy                           1.00      1780\n",
      "    macro avg       1.00      1.00      1.00      1780\n",
      " weighted avg       1.00      1.00      1.00      1780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the classifier (Logistic Regression)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict the categories for the training data\n",
    "y_train_pred = clf.predict(X_train_tfidf)\n",
    "\n",
    "# Generate the classification report for the training data\n",
    "train_report = classification_report(y_train, y_train_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "# Print the classification report for the training data \n",
    "print(\"Training Classification Report:\\n\", train_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-GsqwyPl3oe"
   },
   "source": [
    "6. Report on test metrics of the first classifier. Use the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.93      0.94      0.94       101\n",
      "entertainment       1.00      0.94      0.97        81\n",
      "     politics       0.94      0.98      0.96        83\n",
      "        sport       0.98      1.00      0.99        98\n",
      "         tech       0.98      0.96      0.97        82\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.97      0.96      0.96       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict the categories for the test data\n",
    "y_test_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Generate the classification report for the test data\n",
    "test_report = classification_report(y_test, y_test_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "# Print the classification report for the test data \n",
    "print(\"Test Classification Report:\\n\", test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7QAegZdl9GC"
   },
   "source": [
    "7. Create the second topic classifier. Include a vectorizer if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Create the Support Vector Classifier with a pipeline\n",
    "svm_classifier = make_pipeline(vectorizer, SVC(kernel='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0xt6P1zmBpe"
   },
   "source": [
    "8. Report on the training metrics of the second classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report for Second Classifier (SVM):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00       409\n",
      "entertainment       1.00      1.00      1.00       305\n",
      "     politics       1.00      1.00      1.00       334\n",
      "        sport       1.00      1.00      1.00       413\n",
      "         tech       1.00      1.00      1.00       319\n",
      "\n",
      "     accuracy                           1.00      1780\n",
      "    macro avg       1.00      1.00      1.00      1780\n",
      " weighted avg       1.00      1.00      1.00      1780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit the pipeline with training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the training data\n",
    "y_train_pred_svm = svm_classifier.predict(X_train)\n",
    "\n",
    "# Generate the classification report for the training data\n",
    "train_report_svm = classification_report(y_train, y_train_pred_svm, target_names=label_encoder.classes_)\n",
    "\n",
    "# Print the classification report for the training data \n",
    "print(\"Training Classification Report for Second Classifier (SVM):\\n\", train_report_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRkrC1DJmF8W"
   },
   "source": [
    "9. Report on the test metrics of the second classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report for Second Classifier (SVM):\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.93      0.95       101\n",
      "entertainment       1.00      0.98      0.99        81\n",
      "     politics       0.93      0.99      0.96        83\n",
      "        sport       0.98      1.00      0.99        98\n",
      "         tech       0.99      0.99      0.99        82\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Predict the categories for the test data\n",
    "y_test_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "#Generate the classification report for the test data\n",
    "test_report_svm = classification_report(y_test, y_test_pred_svm, target_names=label_encoder.classes_)\n",
    "\n",
    "#Print the classification report for the test data \n",
    "print(\"Test Classification Report for Second Classifier (SVM):\\n\", test_report_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD0lZ9BMmKFP"
   },
   "source": [
    "10. How do the two classifiers compare in metrics? Do they overfit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both classifiers (Logistic Regression and SVM) show overfitting, \n",
    "#with perfect performance on the training set (1.00 precision, recall, and accuracy) but a slight drop in performance on the test set.\n",
    "\n",
    "#Classifier 1 achieves 0.96 accuracy on the test data, while Classifier 2 (SVM) performs slightly better with 0.98 accuracy. \n",
    "\n",
    "#Despite the drop in accuracy, both classifiers maintain strong precision, recall, and F1-scores, indicating good generalization to new data.\n",
    "\n",
    "#Overall, the SVM model outperforms the first classifier with slightly better test accuracy and overall metrics."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSPtUiAw999hLNbE9gTWYj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
